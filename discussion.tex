Using the experimental data and reinforcement learning agents, we could provide evidence that the exponential utility function is not able to capture all human risk behaviour under uncertainty. While the EUF implies a time-independent policy, we found that the majority of our participants acted in a time-dependent manner. The parametrized $\text{sinh}$ utility function, on the other hand, was able to model these participants fairly well.

However, much work is left to be done both in the theoretical and the empirical realm. 
For the theoretical part effort is needed to find a way to solve the inverse reinforcement learning problem more directly, i.e. to obtain a utility function directly from behavioural data without having to search a vast parameter space.
Furthermore, online methods like Q-learning can be explored to model human behavior better by considering the order of the episodes and the learning process.

For the empirical part it would be interesting to conduct a reversed experiment where the house prices increase over time until the market transitions into a state of recession. This could show whether the observed risk seeking behaviour of many participants was only induced by high waiting costs. 